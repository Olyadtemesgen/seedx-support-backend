# SeedX Support Backend

## ğŸ“¦ Project Overview

This backend powers the SeedX Support system. It includes secure authentication, ticketing, messaging, and AI message streaming, all powered by FastAPI, PostgreSQL, SQLAlchemy, and Docker.

---

## âœ… Evaluation Criteria

### 1. ğŸ§¼ Code Quality & OOP

- Clean, readable, fully type-annotated Python code.
- Follows PEP8, formatted with `black` and `isort`.
- Uses Object-Oriented Design:
  - Abstract `RepositoryInterface` with typed generics.
  - Service layer classes like `UserService`, `AuthService`.
- Good separation of concerns:
  - API (`resource.py`), logic (`service.py`), database (`repository.py`).

---

### 2. ğŸ— Architecture

- Modular layout under `src/seedx_support_backend/`:
  - `users/`, `tickets/`, `messages/`, `infrastructure/`
- Service/Repository pattern separates logic from DB operations.
- App factory pattern (`create_app`) used for flexibility and testing.
- Configuration management with `pydantic-settings`.

---
## ğŸ—‚ï¸ Project Structure

```
seedx-support-backend/
â”‚
â”œâ”€â”€ alembic/                        # DB migration scripts
â”‚   â”œâ”€â”€ versions/                   # Autogenerated migration files
â”‚   â””â”€â”€ env.py                      # Alembic env config
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py                      # App factory for FastAPI
â”‚   â”œâ”€â”€ config.py                   # Environment and settings using pydantic-settings
â”‚   â”œâ”€â”€ middleware.py               # Middleware setup (CORS, etc.)
â”‚
â”‚   â””â”€â”€ seedx_support_backend/
â”‚       â”œâ”€â”€ infrastructure/
â”‚       â”‚   â”œâ”€â”€ database.py         # SQLAlchemy base and engine
â”‚       â”‚   â”œâ”€â”€ repository.py       # Abstract repository interfaces
â”‚
â”‚       â”œâ”€â”€ users/
â”‚       â”‚   â”œâ”€â”€ models.py           # SQLAlchemy User model
â”‚       â”‚   â”œâ”€â”€ core.py             # Pydantic schemas for User
â”‚       â”‚   â”œâ”€â”€ service.py          # Business logic for users
â”‚       â”‚   â”œâ”€â”€ resource.py         # API routes for auth & user
â”‚       â”‚   â””â”€â”€ repository.py       # User repository
â”‚
â”‚       â”œâ”€â”€ tickets/
â”‚       â”‚   â”œâ”€â”€ models.py           # Ticket DB model
â”‚       â”‚   â”œâ”€â”€ core.py             # Pydantic schemas for tickets
â”‚       â”‚   â”œâ”€â”€ service.py          # Ticket logic
â”‚       â”‚   â””â”€â”€ resource.py         # Ticket API routes
â”‚
â”‚       â”œâ”€â”€ messages/
â”‚       â”‚   â”œâ”€â”€ models.py           # Message DB model
â”‚       â”‚   â”œâ”€â”€ core.py             # Pydantic schemas for messages
â”‚       â”‚   â”œâ”€â”€ service.py          # Message logic
â”‚       â”‚   â””â”€â”€ resource.py         # Message API routes
â”‚
â”‚       â””â”€â”€ ai/
â”‚           â”œâ”€â”€ service.py          # AI integration with Groq
â”‚           â””â”€â”€ resource.py         # Streaming endpoint
â”‚
â”œâ”€â”€ Dockerfile                      # Docker image definition
â”œâ”€â”€ docker-compose.yml              # Compose config for app & db
â”œâ”€â”€ .env                            # Environment variables
â”œâ”€â”€ pyproject.toml                  # Poetry project definition
â”œâ”€â”€ Makefile                        # CLI tasks (build, up, down, test)
â””â”€â”€ README.md                       # Project overview
```

### 3. ğŸ§ª Technical Requirements

- **Authentication**:
  - JWT-based auth using `pyjwt`, `passlib`, and FastAPI security utils.
  - Signup & login with hashed password handling.
- **Database Integration**:
  - PostgreSQL via SQLAlchemy 2.0.
  - Alembic for schema migrations.
- **AI Streaming**:
  - Groq-compatible streaming hook included.
  - Endpoint for AI-generated responses (pluggable logic).
- **Docker Setup**:
  - Multi-stage Dockerfile for minimal runtime size.
  - `docker-compose.yml` includes app + Postgres DB.
  - `.env` for secrets and config.

---

### 4. ğŸ“˜ Documentation

#### Setup Instructions

```bash
# Clone the repo
git clone <https://github.com/Olyadtemesgen/seedx-support-backend>

# Add env vars
cp .env.example .env

# Build and run
make build
make up

# Run DB migrations
docker-compose exec app alembic upgrade head # this is already included in the docker-compose file (we don't need to run it manually, just incase :))
```

## API Endpoints

| Method | Path                            | Description                          |
|--------|---------------------------------|--------------------------------------|
| POST   | /auth/signup                    | Create a new user                    |
| POST   | /auth/login                     | Login and receive JWT                |
| GET    | /tickets                        | List user's tickets                  |
| POST   | /tickets                        | Create a new support ticket          |
| GET    | /tickets/{ticket_id}           | Get a specific ticket with messages  |
| POST   | /tickets/{ticket_id}/messages  | Add a message to a ticket            |
| GET    | /tickets/{ticket_id}/ai-response | Stream an AI response (SSE)        |

FastAPI docs available at: [http://localhost:8443/docs](http://localhost:8443/docs)


> ğŸ”— FastAPI docs available at: `http://localhost:8443/docs`

---

## ğŸ”§ Environment Variables (.env)

```env
DATABASE_URL=postgresql://postgres:postgres@db:5432/supportdb
JWT_SECRET=jwt_secret....
JWT_KEY=your_jwt_key
EXPIRE_MINUTES=60
GROK_API_KEY=your_groq_key
GROK_API_URL=https://api.groq.com
ALLOWED_ORIGINS=http://localhost,http://localhost:3000

```
## ğŸ’¡ Design Decisions

- Used `pydantic-settings` for clean env config loading.
- All routes versionable and easily testable due to app factory.
- Repository pattern makes mocking easy during tests.
- Streaming allows real-time AI use cases.
- Docker ensures consistent reproducibility and deployment.

---

## ğŸ§ª Testing

The testing is not added yet but we can Include tests for:

- Auth service  
- Token logic  
- Message validation  
- Repository behavior  

---

## ğŸ§© Final Thoughts

The system is scalable, testable, and well-isolated by concern.  
Designed to integrate seamlessly with both internal support staff workflows and future AI augmentation pipelines.
